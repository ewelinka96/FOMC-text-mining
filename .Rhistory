library(topicmodels)
library(SentimentAnalysis)
library(igraph)
library(ggraph)
library(widyr)
library(viridis)
library(plotly)
library(ggplot2)
library(lubridate)
library(wordcloud2)
library(stringr)
library(tidyr)
DATA_DIR <- "~/Desktop/FOMC-text-mining/Statements"
fomc_2006 <- readtext(paste0(DATA_DIR, "/2006/*"))
fomc_2007 <- readtext(paste0(DATA_DIR, "/2007/*"))
fomc_2008 <- readtext(paste0(DATA_DIR, "/2008/*"))
fomc_2009 <- readtext(paste0(DATA_DIR, "/2009/*"))
fomc_2010 <- readtext(paste0(DATA_DIR, "/2010/*"))
fomc_2011 <- readtext(paste0(DATA_DIR, "/2011/*"))
fomc_2012 <- readtext(paste0(DATA_DIR, "/2012/*"))
fomc_2013 <- readtext(paste0(DATA_DIR, "/2013/*"))
fomc_2014 <- readtext(paste0(DATA_DIR, "/2014/*"))
fomc_2015 <- readtext(paste0(DATA_DIR, "/2015/*"))
fomc_2016 <- readtext(paste0(DATA_DIR, "/2016/*"))
fomc_2017 <- readtext(paste0(DATA_DIR, "/2017/*"))
fomc_2018 <- readtext(paste0(DATA_DIR, "/2018/*"))
# Binding data
statements <- rbind(fomc_2006, fomc_2007, fomc_2008, fomc_2009, fomc_2010, fomc_2011,
fomc_2012, fomc_2013, fomc_2014, fomc_2015, fomc_2016, fomc_2017, fomc_2018)
# Removing files from memory
remove(fomc_2006, fomc_2007, fomc_2008, fomc_2009, fomc_2010, fomc_2011,
fomc_2012, fomc_2013, fomc_2014, fomc_2015, fomc_2016, fomc_2017, fomc_2018)
# adding an unique ID
statements <- statements %>% mutate(ID = 1:n())
# setting column names
colnames(statements) <- c("Date", "Text", "ID")
# modification of doc_id column - changing it to date column
statements$Date <- gsub(".txt", "", statements$Date)
statements$Date <- as.Date(statements$Date, "%Y%m%d")
statements_all <- as.vector(statements$Text)
corpus_all <- VCorpus(VectorSource(statements_all))
corpus_clean <- corpus_all %>%
tm_map(tolower) %>%
tm_map(removeWords, stopwords("en")) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace) %>%
tm_map(removeNumbers) %>%
tm_map(PlainTextDocument)
df_corpus <- data.frame(text = unlist(sapply(corpus_clean, `[`, "content")), stringsAsFactors = F)
df_corpus <- df_corpus %>% mutate(doc_id = 1:n())
statements_clean <- statements %>%
mutate(cleaned_text = df_corpus$text)
statements_clean$cleaned_text <- lemmatize_strings(statements_clean$cleaned_text)
count_cleaned_word <- statements_clean %>%
unnest_tokens(word_count, cleaned_text) %>%
count(ID, word_count, sort = T) %>%
group_by(ID) %>%
summarize(word_cleaned_count = sum(n))
statements_clean_count <- left_join(statements_clean, count_cleaned_word, by = 'ID')
count_word <- statements_clean_count %>%
unnest_tokens(word_count, Text) %>%
count(ID, word_count, sort = T) %>%
group_by(ID) %>%
summarize (word_count = sum(n))
statements_final <- left_join(statements_clean_count, count_word, by = 'ID')
myplot <- statements_final %>%
select(Date, word_count) %>%
ggplot() +
geom_line(aes(x = Date,
y = word_count),
color = viridis(10)[3]) +
labs(x = "Date",
y = "Number of words",
title = "Length of FOMC statements in time") +
scale_x_date(date_breaks = "1 year",
date_labels = "%Y") +
theme_minimal()
ggplotly(myplot)
dtm <- TermDocumentMatrix(corpus_clean)
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing=TRUE)
d <- data.frame(word = names(v), freq=v)
set.seed(1234)
wordcloud2(d %>% arrange(desc(freq)) %>% head(100), color=viridis(100, direction = -1), shape='circle', size=0.2, minRotation = -pi/2, ellipticity = .8)
tdm_tm <- DocumentTermMatrix(corpus_clean)
ap_lda <- LDA(tdm_tm, k = 5, control = list(seed = 1234))
ap_topics <- tidy(ap_lda, matrix = "beta")
tdm_tm <- DocumentTermMatrix(corpus_clean)
ap_lda <- LDA(tdm_tm, k = 5, control = list(seed = 1234))
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
top_n(8, beta) %>%
ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE, fill = viridis(40)) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
labs(y="Value of beta parameter", x="") +
scale_x_reordered() +
theme_minimal()
tdm_tm <- DocumentTermMatrix(corpus_clean)
ap_lda <- LDA(tdm_tm, k = 5, control = list(seed = 1234))
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
top_n(8, beta) %>%
ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE, fill = viridis(40)) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
labs(y="Value of beta parameter", x="") +
scale_x_reordered() +
theme_minimal()
tdm_tm <- DocumentTermMatrix(corpus_clean)
ap_lda <- LDA(tdm_tm, k = 5, control = list(seed = 1234))
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
top_n(8, beta) %>%
ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE, fill = viridis(40)) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
labs(y="Value of beta parameter", x="") +
scale_x_reordered() +
theme_minimal()
tidy_statement <- statements_clean %>%
mutate(year = year(Date)) %>%
group_by(year) %>%
ungroup() %>%
unnest_tokens(word, cleaned_text)
tidy_statement <- tidy_statement %>%
select(year, ID, word)
LM_dict <- loadDictionaryLM()
LM_dict_pos <- as.data.frame(LM_dict$positiveWords)
LM_dict_pos$sentiment <- c("positive")
colnames(LM_dict_pos)[1] <- "word"
LM_dict_neg <- as.data.frame(LM_dict$negativeWords)
LM_dict_neg$sentiment <- c("negative")
colnames(LM_dict_neg)[1] <- "word"
LM_dict <- rbind(LM_dict_pos, LM_dict_neg)
statement_sentiment <- tidy_statement %>%
inner_join(LM_dict) %>%
count(year, ID, sentiment) %>%
spread(sentiment, n, fill=0) %>%
mutate(sentiment = positive - negative)
sentiment_plot <- ggplot(statement_sentiment, aes(as.factor(ID),
sentiment,
fill = sentiment,
text = paste("Statement id: ", ID,
"<br>Sentiment value: ", sentiment))) +
geom_col(show.legend = FALSE, ) +
facet_wrap(~year, ncol = 3, scales = "free_x") +
labs(x="", y="Sentiment") +
scale_fill_viridis_c(direction=-1) +
theme_minimal()
ggplotly(sentiment_plot, tooltip = "text") %>%
layout(autosize = F, width = 600, height = 800)
word_counts_zipf <- statements_clean_count %>%
mutate(year = year(Date)) %>%
unnest_tokens(word_count, cleaned_text) %>%
count(word_count, sort = T)
word_count <- word_counts_zipf
colnames(word_count) <- c("word", "count")
word_count <- word_count %>%
mutate(word = factor(word, levels = word),
rank = row_number(),
zipfs_freq = ifelse(rank == 1, count, dplyr::first(count) / rank))
large_zipf <- as.vector(word_count$word[1:17])
small_zipf <- as.vector(word_count$word[300:1174])
corpus_clean <- corpus_clean %>% tm_map(removeWords, large_zipf)
corpus_clean <- corpus_clean %>% tm_map(removeWords, small_zipf)
df_corpus <- data.frame(text = unlist(sapply(corpus_clean, `[`, "content")), stringsAsFactors = F)
df_corpus <- df_corpus %>% mutate(doc_id = 1:n())
statements_clean <- statements %>%
mutate(cleaned_text = df_corpus$text)
statements_clean$cleaned_text <- lemmatize_strings(statements_clean$cleaned_text)
statements_words <- statements_clean %>%
mutate(year = year(Date)) %>%
unnest_tokens(word_count, cleaned_text) %>%
count(ID, year, word_count, sort = T)
statements_words_id <- statements_words %>%
bind_tf_idf(word_count, ID, n) %>%
arrange(desc(tf_idf))
dtm <- TermDocumentMatrix(corpus_clean)
m <- as.matrix(dtm)
v <- sort(rowSums(m), decreasing=TRUE)
d <- data.frame(word = names(v), freq=v)
set.seed(1234)
wordcloud2(d %>% arrange(desc(freq)) %>% head(100), color=viridis(100, direction = -1), shape='circle', size=0.2, minRotation = -pi/2, ellipticity = .8)
tdm_tm <- DocumentTermMatrix(corpus_clean)
ap_lda <- LDA(tdm_tm, k = 5, control = list(seed = 1234))
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
top_n(8, beta) %>%
ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE, fill = viridis(40)) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
labs(y="Value of beta parameter", x="") +
scale_x_reordered() +
theme_minimal()
tidy_statement <- statements_clean %>%
mutate(year = year(Date)) %>%
group_by(year) %>%
ungroup() %>%
unnest_tokens(word, cleaned_text)
tidy_statement <- tidy_statement %>%
select(year, ID, word)
LM_dict <- loadDictionaryLM()
LM_dict_pos <- as.data.frame(LM_dict$positiveWords)
LM_dict_pos$sentiment <- c("positive")
colnames(LM_dict_pos)[1] <- "word"
LM_dict_neg <- as.data.frame(LM_dict$negativeWords)
LM_dict_neg$sentiment <- c("negative")
colnames(LM_dict_neg)[1] <- "word"
LM_dict <- rbind(LM_dict_pos, LM_dict_neg)
statement_sentiment <- tidy_statement %>%
inner_join(LM_dict) %>%
count(year, ID, sentiment) %>%
spread(sentiment, n, fill=0) %>%
mutate(sentiment = positive - negative)
sentiment_plot <- ggplot(statement_sentiment, aes(as.factor(ID),
sentiment,
fill = sentiment,
text = paste("Statement id: ", ID,
"<br>Sentiment value: ", sentiment))) +
geom_col(show.legend = FALSE, ) +
facet_wrap(~year, ncol = 3, scales = "free_x") +
labs(x="", y="Sentiment") +
scale_fill_viridis_c(direction=-1) +
theme_minimal()
ggplotly(sentiment_plot, tooltip = "text") %>%
layout(autosize = F, width = 600, height = 800)
ggplotly(sentiment_plot, tooltip = "text") %>%
layout(autosize = F, width = 600, height = 800)
ggplotly(sentiment_plot, tooltip = "text") %>%
layout(autosize = F, width = 600, height = 600)
ggplotly(sentiment_plot, tooltip = "text") %>%
layout(autosize = F, width = 600, height = 550)
ggplotly(sentiment_plot, tooltip = "text") %>%
layout(autosize = F, width = 600, height = 500)
ggplotly(sentiment_plot, tooltip = "text") %>%
layout(autosize = F, width = 600, height = 600)
View(statement_sentiment)
tidy_statement <- statements_clean %>%
mutate(year = year(Date)) %>%
group_by(year) %>%
ungroup() %>%
unnest_tokens(word, cleaned_text)
tidy_statement <- tidy_statement %>%
select(year, ID, word)
LM_dict <- loadDictionaryLM()
LM_dict_pos <- as.data.frame(LM_dict$positiveWords)
LM_dict_pos$sentiment <- c("positive")
colnames(LM_dict_pos)[1] <- "word"
LM_dict_neg <- as.data.frame(LM_dict$negativeWords)
LM_dict_neg$sentiment <- c("negative")
colnames(LM_dict_neg)[1] <- "word"
LM_dict <- rbind(LM_dict_pos, LM_dict_neg)
statement_sentiment <- tidy_statement %>%
inner_join(LM_dict) %>%
count(year, ID, sentiment) %>%
spread(sentiment, n, fill=0) %>%
mutate(sentiment = positive - negative)
sentiment_1 <- statement_sentiment %>% filter(year <= 2014)
sentiment_2 <- statement_sentiment %>% filter(year > 2014)
sentiment_plot_1 <- ggplot(sentiment_1, aes(as.factor(ID),
sentiment,
fill = sentiment,
text = paste("Statement id: ", ID,
"<br>Sentiment value: ", sentiment))) +
geom_col(show.legend = FALSE, ) +
facet_wrap(~year, ncol = 3, scales = "free_x") +
labs(x="", y="Sentiment") +
scale_fill_viridis_c(direction=-1) +
theme_minimal()
sentiment_plot_2 <- ggplot(sentiment_2, aes(as.factor(ID),
sentiment,
fill = sentiment,
text = paste("Statement id: ", ID,
"<br>Sentiment value: ", sentiment))) +
geom_col(show.legend = FALSE, ) +
facet_wrap(~year, ncol = 3, scales = "free_x") +
labs(x="", y="Sentiment") +
scale_fill_viridis_c(direction=-1) +
theme_minimal()
ggplotly(sentiment_plot_1, tooltip = "text") %>%
layout(autosize = F, width = 600, height = 550)
ggplotly(sentiment_plot_2, tooltip = "text") %>%
layout(autosize = F, width = 600, height = 550)
tidy_statement <- statements_clean %>%
mutate(year = year(Date)) %>%
group_by(year) %>%
ungroup() %>%
unnest_tokens(word, cleaned_text)
tidy_statement <- tidy_statement %>%
select(year, ID, word)
LM_dict <- loadDictionaryLM()
LM_dict_pos <- as.data.frame(LM_dict$positiveWords)
LM_dict_pos$sentiment <- c("positive")
colnames(LM_dict_pos)[1] <- "word"
LM_dict_neg <- as.data.frame(LM_dict$negativeWords)
LM_dict_neg$sentiment <- c("negative")
colnames(LM_dict_neg)[1] <- "word"
LM_dict <- rbind(LM_dict_pos, LM_dict_neg)
statement_sentiment <- tidy_statement %>%
inner_join(LM_dict) %>%
count(year, ID, sentiment) %>%
spread(sentiment, n, fill=0) %>%
mutate(sentiment = positive - negative)
sentiment_1 <- statement_sentiment %>% filter(year <= 2014)
sentiment_2 <- statement_sentiment %>% filter(year > 2014)
sentiment_plot_1 <- ggplot(sentiment_1, aes(as.factor(ID),
sentiment,
fill = sentiment,
text = paste("Statement id: ", ID,
"<br>Sentiment value: ", sentiment))) +
geom_col(show.legend = FALSE, ) +
facet_wrap(~year, ncol = 3, scales = "free_x") +
labs(x="", y="Sentiment") +
scale_fill_viridis_c(direction=-1) +
theme_minimal()
sentiment_plot_2 <- ggplot(sentiment_2, aes(as.factor(ID),
sentiment,
fill = sentiment,
text = paste("Statement id: ", ID,
"<br>Sentiment value: ", sentiment))) +
geom_col(show.legend = FALSE, ) +
facet_wrap(~year, ncol = 3, scales = "free_x") +
labs(x="", y="Sentiment") +
scale_fill_viridis_c(direction=-1) +
theme_minimal()
ggplotly(sentiment_plot_1, tooltip = "text")
ggplotly(sentiment_plot_2, tooltip = "text")
tidy_statement <- statements_clean %>%
mutate(year = year(Date)) %>%
group_by(year) %>%
ungroup() %>%
unnest_tokens(word, cleaned_text)
tidy_statement <- tidy_statement %>%
select(year, ID, word)
LM_dict <- loadDictionaryLM()
LM_dict_pos <- as.data.frame(LM_dict$positiveWords)
LM_dict_pos$sentiment <- c("positive")
colnames(LM_dict_pos)[1] <- "word"
LM_dict_neg <- as.data.frame(LM_dict$negativeWords)
LM_dict_neg$sentiment <- c("negative")
colnames(LM_dict_neg)[1] <- "word"
LM_dict <- rbind(LM_dict_pos, LM_dict_neg)
statement_sentiment <- tidy_statement %>%
inner_join(LM_dict) %>%
count(year, ID, sentiment) %>%
spread(sentiment, n, fill=0) %>%
mutate(sentiment = positive - negative)
sentiment_plot <- ggplot(statement_sentiment, aes(as.factor(ID),
sentiment,
fill = sentiment,
text = paste("Statement id: ", ID,
"<br>Sentiment value: ", sentiment))) +
geom_col(show.legend = FALSE, ) +
facet_wrap(~year, ncol = 3, scales = "free_x") +
labs(x="", y="Sentiment") +
scale_fill_viridis_c(direction=-1) +
theme_minimal()
ggplotly(sentiment_plot, tooltip = "text") %>%
layout(autosize = F, width = 600, height = 550)
tidy_statement <- statements_clean %>%
mutate(year = year(Date)) %>%
group_by(year) %>%
ungroup() %>%
unnest_tokens(word, cleaned_text)
tidy_statement <- tidy_statement %>%
select(year, ID, word)
LM_dict <- loadDictionaryLM()
LM_dict_pos <- as.data.frame(LM_dict$positiveWords)
LM_dict_pos$sentiment <- c("positive")
colnames(LM_dict_pos)[1] <- "word"
LM_dict_neg <- as.data.frame(LM_dict$negativeWords)
LM_dict_neg$sentiment <- c("negative")
colnames(LM_dict_neg)[1] <- "word"
LM_dict <- rbind(LM_dict_pos, LM_dict_neg)
statement_sentiment <- tidy_statement %>%
inner_join(LM_dict) %>%
count(year, ID, sentiment) %>%
spread(sentiment, n, fill=0) %>%
mutate(sentiment = positive - negative)
sentiment_plot <- ggplot(statement_sentiment, aes(as.factor(ID),
sentiment,
fill = sentiment,
text = paste("Statement id: ", ID,
"<br>Sentiment value: ", sentiment))) +
geom_col(show.legend = FALSE, ) +
facet_wrap(~year, ncol = 4, scales = "free_x") +
labs(x="", y="Sentiment") +
scale_fill_viridis_c(direction=-1) +
theme_minimal()
ggplotly(sentiment_plot, tooltip = "text") %>%
layout(autosize = F, width = 800, height = 550)
tidy_statement <- statements_clean %>%
mutate(year = year(Date)) %>%
group_by(year) %>%
ungroup() %>%
unnest_tokens(word, cleaned_text)
tidy_statement <- tidy_statement %>%
select(year, ID, word)
LM_dict <- loadDictionaryLM()
LM_dict_pos <- as.data.frame(LM_dict$positiveWords)
LM_dict_pos$sentiment <- c("positive")
colnames(LM_dict_pos)[1] <- "word"
LM_dict_neg <- as.data.frame(LM_dict$negativeWords)
LM_dict_neg$sentiment <- c("negative")
colnames(LM_dict_neg)[1] <- "word"
LM_dict <- rbind(LM_dict_pos, LM_dict_neg)
statement_sentiment <- tidy_statement %>%
inner_join(LM_dict) %>%
count(year, ID, sentiment) %>%
spread(sentiment, n, fill=0) %>%
mutate(sentiment = positive - negative)
sentiment_plot <- ggplot(statement_sentiment, aes(as.factor(ID),
sentiment,
fill = sentiment,
text = paste("Statement id: ", ID,
"<br>Sentiment value: ", sentiment))) +
geom_col(show.legend = FALSE, ) +
facet_wrap(~year, ncol = 4, scales = "free_x") +
labs(x="", y="Sentiment") +
scale_fill_viridis_c(direction=-1) +
theme_minimal()
ggplotly(sentiment_plot, tooltip = "text") %>%
layout(autosize = F, width = 700, height = 550)
tidy_statement <- statements_clean %>%
mutate(year = year(Date)) %>%
group_by(year) %>%
ungroup() %>%
unnest_tokens(word, cleaned_text)
tidy_statement <- tidy_statement %>%
select(year, ID, word)
LM_dict <- loadDictionaryLM()
LM_dict_pos <- as.data.frame(LM_dict$positiveWords)
LM_dict_pos$sentiment <- c("positive")
colnames(LM_dict_pos)[1] <- "word"
LM_dict_neg <- as.data.frame(LM_dict$negativeWords)
LM_dict_neg$sentiment <- c("negative")
colnames(LM_dict_neg)[1] <- "word"
LM_dict <- rbind(LM_dict_pos, LM_dict_neg)
statement_sentiment <- tidy_statement %>%
inner_join(LM_dict) %>%
count(year, ID, sentiment) %>%
spread(sentiment, n, fill=0) %>%
mutate(sentiment = positive - negative)
sentiment_plot <- ggplot(statement_sentiment, aes(as.factor(ID),
sentiment,
fill = sentiment,
text = paste("Statement id: ", ID,
"<br>Sentiment value: ", sentiment))) +
geom_col(show.legend = FALSE, ) +
facet_wrap(~year, ncol = 4, scales = "free_x") +
labs(x="", y="Sentiment") +
scale_fill_viridis_c(direction=-1) +
theme_minimal()
ggplotly(sentiment_plot, tooltip = "text") %>%
layout(autosize = F, width = 750, height = 550)
tidy_statement <- statements_clean %>%
mutate(year = year(Date)) %>%
group_by(year) %>%
ungroup() %>%
unnest_tokens(word, cleaned_text)
tidy_statement <- tidy_statement %>%
select(year, ID, word)
LM_dict <- loadDictionaryLM()
LM_dict_pos <- as.data.frame(LM_dict$positiveWords)
LM_dict_pos$sentiment <- c("positive")
colnames(LM_dict_pos)[1] <- "word"
LM_dict_neg <- as.data.frame(LM_dict$negativeWords)
LM_dict_neg$sentiment <- c("negative")
colnames(LM_dict_neg)[1] <- "word"
LM_dict <- rbind(LM_dict_pos, LM_dict_neg)
statement_sentiment <- tidy_statement %>%
inner_join(LM_dict) %>%
count(year, ID, sentiment) %>%
spread(sentiment, n, fill=0) %>%
mutate(sentiment = positive - negative)
sentiment_plot <- ggplot(statement_sentiment, aes(as.factor(ID),
sentiment,
fill = sentiment,
text = paste("Statement id: ", ID,
"<br>Sentiment value: ", sentiment))) +
geom_col(show.legend = FALSE, ) +
facet_wrap(~year, ncol = 4, scales = "free_x") +
labs(x="", y="Sentiment") +
scale_fill_viridis_c(direction=-1) +
theme_minimal()
ggplotly(sentiment_plot, tooltip = "text") %>%
layout(autosize = F, width = 750, height = 500)
